import {
    GrammarIR, RuleIR, ElementIR,
    ProductRuleIR, BranchRuleIR
} from './analyzer';

export class RustParserGenerator {
    private ir: GrammarIR;

    constructor(ir: GrammarIR) {
        this.ir = ir;
    }

    public generate(): string {
        const typeDefs = this.generateTypeDefs();
        const traitDef = this.generateParserTrait();

        return `
// ==========================================
//  Generated by Script
//  DO NOT EDIT THIS FILE DIRECTLY
// ==========================================
  
  use std::collections::HashSet;
  
  // --- AST Types ---
  ${typeDefs}
  
  // --- Parser Trait ---
  ${traitDef}
  `;
    }

    // -------------------------------------------------------------------------
    // 1. 型定義 (Structs & Enums)
    // -------------------------------------------------------------------------

    private generateTypeDefs(): string {
        const code: string[] = [];

        for (const [_, rule] of this.ir.rules) {
            if (rule.kind === 'Branch') {
                const variants = rule.variants
                    .map(v => `    ${v.rustVariantName}(${v.targetRule}),`)
                    .join('\n');

                code.push(`
  #[derive(Debug, Clone)]
  pub enum ${rule.rustName} {
  ${variants}
  }`);
            } else {
                // Product
                const fields = rule.elements
                    .filter((e): e is Extract<ElementIR, { kind: 'NonTerminal' }> => e.kind === 'NonTerminal')
                    .map(e => {
                        let typeStr = this.getRustType(e.targetRule, e.modifier);
                        if (e.isBoxed) {
                            typeStr = `Box<${typeStr}>`;
                        }
                        return `    pub ${e.rustFieldName}: ${typeStr},`;
                    })
                    .join('\n');

                code.push(`
  #[derive(Debug, Clone)]
  pub struct ${rule.rustName} {
  ${fields}
  }`);
            }
        }
        return code.join('\n');
    }

    // -------------------------------------------------------------------------
    // 2. Parser Trait & Logic
    // -------------------------------------------------------------------------

    private generateParserTrait(): string {
        // Hooks (抽象メソッド)
        const hookDecls = Array.from(this.ir.hooks.values()).map(h =>
            `    /// ${h.doc}\n    fn ${h.methodName}(&mut self) -> Result<${h.returnType}, Self::Error>;`
        ).join('\n');

        // Sync Points (エラー回復用)
        const syncTokens = Array.from(this.ir.analysis.syncPoints)
            .map(t => `"${t}"`)
            .join(', ');

        // 各ルールのパースメソッド
        const methods = Array.from(this.ir.rules.values())
            .map(rule => this.generateParseMethod(rule))
            .join('\n');

        return `
  pub trait BaseParser {
      type Error;
      fn peek_token(&self) -> Option<&str>;
      fn consume_token(&mut self) -> Option<String>;
      fn expect_token(&mut self, expected: &str) -> Result<(), Self::Error>;
      fn report_error(&mut self, msg: String) -> Self::Error;
  }
  
  pub trait GeneratedParser: BaseParser + Sized {
      // --- DI Hooks ---
  ${hookDecls}
  
      // --- Error Recovery ---
      fn synchronize(&mut self) {
          // Simple panic mode recovery: skip until sync point
          let sync_points = [${syncTokens}];
          while let Some(token) = self.peek_token() {
              if sync_points.contains(&token) {
                  return;
              }
              self.consume_token();
          }
      }
  
      // --- Parser Methods ---
  ${methods}
  }
  `;
    }

    private generateParseMethod(rule: RuleIR): string {
        const returnType = rule.rustName;
        const body = rule.kind === 'Branch'
            ? this.generateBranchLogic(rule)
            : this.generateProductLogic(rule);

        return `
      fn parse_${rule.rustName}(&mut self) -> Result<${returnType}, Self::Error> {
  ${body}
      }`;
    }

    // -------------------------------------------------------------------------
    // Branch Logic (LL(1) Switch)
    // -------------------------------------------------------------------------

    private generateBranchLogic(rule: BranchRuleIR): string {
        const cases: string[] = [];

        // 各バリアントについて、First集合をチェックして分岐
        for (const variant of rule.variants) {
            const firstSet = this.ir.analysis.firstSets.get(variant.targetRule);

            if (firstSet && firstSet.size > 0) {
                // First集合に含まれるトークンなら、そのバリアントをパース
                const condition = this.generateTokenMatchPattern(firstSet);
                cases.push(`
          if let Some(token) = self.peek_token() {
              if ${condition} {
                  let val = self.parse_${variant.targetRule}()?;
                  return Ok(${rule.rustName}::${variant.rustVariantName}(val));
              }
          }`);
            } else {
                // Fallback (Nullableの場合など、あるいはデフォルト)
                // ここでは単純化のため、First集合がない場合は直接試行するロジックにするか、
                // あるいはLL(1)としては到達不能とする
            }
        }

        return `
          // Branch Selection based on First Sets
  ${cases.join('')}
  
          Err(self.report_error(format!("Unexpected token for branch ${rule.rustName}")))
      `;
    }

    // -------------------------------------------------------------------------
    // Product Logic (Sequence)
    // -------------------------------------------------------------------------

    private generateProductLogic(rule: ProductRuleIR): string {
        const steps: string[] = [];
        const fieldNames: string[] = [];

        for (const elem of rule.elements) {
            if (elem.kind === 'Terminal') {
                steps.push(`        self.expect_token("${elem.value}")?;`);
            } else {
                // NonTerminal (Field)
                const fieldName = elem.rustFieldName;
                fieldNames.push(fieldName);

                if (elem.hook) {
                    // Hook呼び出し
                    let call = `self.${elem.hook}()?`;
                    if (elem.isBoxed) call = `Box::new(${call})`;
                    steps.push(`        let ${fieldName} = ${call};`);
                } else {
                    // 通常パース (Modifierに応じたロジック)
                    const logic = this.generateFieldLogic(elem);
                    steps.push(`        let ${fieldName} = ${logic};`);
                }
            }
        }

        // Box化が必要なフィールドはコンストラクタでBox::newする必要があるか？
        // -> generateFieldLogic 内、あるいは代入時に処理済みとする。
        // 今回は `generateFieldLogic` が `Result<T, _>` を返す前提。
        // isBoxed=true の場合、struct定義は Box<T> なので、値も Box::new(val) にする。

        // 構造体の構築
        return `
  ${steps.join('\n')}
          Ok(${rule.rustName} {
              ${fieldNames.join(',\n            ')}
          })
      `;
    }

    private generateFieldLogic(elem: Extract<ElementIR, { kind: 'NonTerminal' }>): string {
        const targetParse = `self.parse_${elem.targetRule}()`;
        const firstSet = this.ir.analysis.firstSets.get(elem.targetRule);

        // 基本のパース呼び出しコード (Box化含む)
        const parseCall = elem.isBoxed
            ? `Ok(Box::new(${targetParse}?))`
            : `${targetParse}`; // 末尾に ? は付けない（後続で処理）

        switch (elem.modifier) {
            case 'None':
                // 必須要素: そのまま実行 (? はここでつける)
                return elem.isBoxed
                    ? `Box::new(${targetParse}?)`
                    : `${targetParse}?`;

            case 'Option':
                // ? (Option): First集合を見て、あればパース、なければNone
                if (!firstSet || firstSet.size === 0) {
                    return `None`; // 理論上ありえないが安全策
                }
                const optCondition = this.generateTokenMatchPattern(firstSet);
                const optParse = elem.isBoxed ? `Box::new(${targetParse}?)` : `${targetParse}?`;

                return `
          if let Some(token) = self.peek_token() {
              if ${optCondition} {
                  Some(${optParse})
              } else {
                  None
              }
          } else {
              None
          }`;

            case 'List':
                // * (List): First集合にマッチする間ループ
                if (!firstSet || firstSet.size === 0) {
                    return `Vec::new()`;
                }
                const loopCondition = this.generateTokenMatchPattern(firstSet);

                // Listの中身はBox化しないのが一般的だが、定義上Boxなら従う
                // (AnalyzerでListはBox化しないようにしているが念のため)
                const listElemParse = elem.isBoxed ? `Box::new(${targetParse}?)` : `${targetParse}?`;

                return `
          {
              let mut list = Vec::new();
              while let Some(token) = self.peek_token() {
                  if ${loopCondition} {
                      list.push(${listElemParse});
                  } else {
                      break;
                  }
              }
              list
          }`;
        }
    }

    // -------------------------------------------------------------------------
    // Helpers
    // -------------------------------------------------------------------------

    private getRustType(ruleName: string, modifier: 'None' | 'List' | 'Option'): string {
        switch (modifier) {
            case 'List': return `Vec<${ruleName}>`;
            case 'Option': return `Option<${ruleName}>`;
            case 'None': return ruleName;
        }
    }

    /**
     * First集合(Set<string>)からRustのmatchパターン条件式を生成
     * 例: token == "fn" || token == "let"
     * (単純な文字列比較として実装。Token Enumがある場合は変更が必要)
     */
    private generateTokenMatchPattern(firstSet: Set<string>): string {
        const checks: string[] = [];

        // First集合には "Literal" などの抽象トークンと、"fn" などの具体キーワードが混ざる可能性がある
        // IR生成時に区別しておくのがベストだが、ここでは文字列判定で生成する

        firstSet.forEach(token => {
            // 実際には Lexer がトークン種別を返す設計が望ましいが、
            // ここではプロトタイプとして文字列表現での比較を行う
            // もしIRに 'Identifier' が含まれていたら、それはキーワード以外の識別子すべてにマッチする必要がある
            // 現状は token 文字列との完全一致で生成
            checks.push(`token == "${token}"`);
        });

        if (checks.length === 0) return "false";
        return `(${checks.join(' || ')})`;
    }
}

export function generateParser(ir: GrammarIR): string {
    const generator = new RustParserGenerator(ir);
    return generator.generate();
}
