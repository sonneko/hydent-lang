import { readFileSync } from 'node:fs';
import {
    GrammarIR, RuleIR, ElementIR,
    ProductRuleIR, BranchRuleIR,
    HookIR
} from './analyze';


const TYPE_DEFINITION_PREFIX = `\
// ==========================================
//  Generated by Script (see /script/index.ts)
//  DO NOT EDIT THIS FILE DIRECTLY
//  In "/src/parser/generated_ast.rs"
// ==========================================

use crate::compiler::arena::{ArenaIter, ArenaBox};
use crate::tokenizer::tokens::Token;
use crate::parser::ast::ASTNode;
use crate::parser::ast::SyncPointBitMap;
use crate::parser::errors::ParseErr;

`;

const PARSER_PREFIX = `\
// ==========================================
//  Generated by Script (see /script/index.ts)
//  DO NOT EDIT THIS FILE DIRECTLY
//  In "/src/parser/generated_parser.rs"
// ==========================================

use crate::compiler::arena::{ArenaBox, ArenaIter, Arena};
use crate::compiler::context::frontend::CompilerFrontendContext;
use crate::compiler::symbol::Symbol;
use crate::parser::errors::{ParseErr, IParseErr};
use crate::parser::base_parser::BaseParser;
use crate::tokenizer::tokens::{Token, Literal, Keyword, Operator, Delimiter};

#[allow(clippy::wildcard_imports)] // because of no knowledge of all ast types
use crate::parser::generated_ast::*;

`;

// Convert concrete syntax to Rust token type
// example: "Int" => "Token::Keyword(Keyword::Int)"
const TOKENS_MAP = ((): Map<string, string> => {
    const csv = readFileSync(`${process.cwd()}/../assets/token_map.csv`, "utf8").toString();
    let map: Map<string, string> = new Map();
    csv.split("\n").forEach(line => {
        const literals = line.split("\"");
        map.set(literals[1], literals[3]);
    });
    return map;
})();


export class RustParserGenerator {
    private ir: GrammarIR;
    private unique_id: number;

    constructor(ir: GrammarIR) {
        this.ir = ir;
        this.unique_id = 0;
    }

    public generate(): [string, string] {
        const typeDefs = this.generateTypeDefs();
        const traitDef = this.generateParserTrait();

        return [`${TYPE_DEFINITION_PREFIX}${typeDefs}`, `${PARSER_PREFIX}${traitDef}`];
    }

    // -------------------------------------------------------------------------
    // 1. Type definition (Structs & Enums)
    // -------------------------------------------------------------------------

    private generateTypeDefs(): string {
        const code: string[] = [];

        for (const [_, rule] of this.ir.rules) {
            if (rule.kind === 'Branch') {
                // Branch
                const variants = rule.variants
                    .map(v => `    ${v.rustVariantName}(${v.targetRule}),`)
                    .join('\n');

                code.push(`
impl ASTNode for ${rule.rustName} {
    const SYNC_POINT_SETS: SyncPointBitMap = SyncPointBitMap::build_map(&[], false, false, false);
    fn get_error_situation(err: ParseErr) -> Option<Self> {
        Some(Self::Invalid)
    }

    fn is_sync_point(token: Option<&Token>) -> bool { false }
}
#[derive(Debug, Copy, Clone, std::hash::Hash, PartialEq, Eq)]
pub enum ${rule.rustName} {
${variants}
    Invalid,
}`);
            } else {
                // Product
                if (rule.elements === undefined) {
                    code.push(`
pub use crate::parser::manual_ast::${rule.rustName};`);
                } else {
                    const fields = rule.elements
                        .filter((e): e is Extract<ElementIR, { kind: 'NonTerminal' }> => e.kind === 'NonTerminal')
                        .map(e => {
                            let typeStr = this.getRustType(e.targetRule, e.modifier);
                            if (e.isBoxed) {
                                typeStr = `ArenaBox<${typeStr}>`;
                            }
                            return `    pub ${e.rustFieldName}: ${typeStr},`;
                        })
                        .join('\n');

                    code.push(`
impl ASTNode for ${rule.rustName} {
    const SYNC_POINT_SETS: SyncPointBitMap = SyncPointBitMap::build_map(&[], false, false, false);
    fn get_error_situation(err: ParseErr) -> Option<Self> {
        None
    }
    fn is_sync_point(token: Option<&Token>) -> bool { false }
}
#[derive(Debug, Copy, Clone, std::hash::Hash, PartialEq, Eq)]
pub struct ${rule.rustName} {
${fields}
}`);
                }
            }
        }
        return code.join('\n');
    }

    // -------------------------------------------------------------------------
    // 2. Parser Trait & Logic
    // -------------------------------------------------------------------------

    private generateParserTrait(): string {
        const methods: string[] = [];

        // methods with default implementations
        for (const [_, rule] of this.ir.rules) {
            switch (rule.kind) {
                case "Branch":
                    methods.push(`#[inline]\n${this.generateBranchMethod(rule)}`);
                    break;
                case "Product":
                    methods.push(`#[inline]\n${this.generateProductMethod(rule)}`);
                    break;
            }
        }

        // methods without default implementations
        for (const [_, rule] of this.ir.hooks) {
            methods.push(this.generateHookMethod(rule));
        }

        return `\
#[allow(non_snake_case)]
pub trait GeneratedParser: BaseParser + Sized {
${methods.join('\n\n')}
}

`;
    }

    // -------------------------------------------------------------------------
    // Method generator
    // -------------------------------------------------------------------------

    private generateBranchMethod(rule: BranchRuleIR): string {
        // TODO: implement this

        // A. Try parsing one peek (L1 grammar)
        const firstChars: string[] = []; // TODO: calculate firstChars in analyze.ts

        if (Array.from(new Set(firstChars)).length === firstChars.length) {
            // there is no same first character, so succeed to LL(1) parsing.
            const branches = firstChars.map((firstChar, i) => {
                const targetRuleRustName = this.getRuleFromName(rule.variants[i].targetRule)!.rustName;
                const rustVariantName = rule.variants[i].rustVariantName;
                return `\
            Some(${TOKENS_MAP.get(firstChar)!}) => Ok(${rule.rustName}::${rustVariantName}(self.parse_${targetRuleRustName}()?)),`;
            });
            const expected = firstChars.map(char => TOKENS_MAP.get(char)!).filter(v => v !== undefined).filter(v => v.trim() !== "");
            return `\
        fn parse_${rule.rustName}(&mut self) -> Result<${rule.rustName}, Self::Error> {
            match self.peek_n::<1>() {
${branches.join("\n")}
                _ => Err(Self::Error::create(self.get_errors_arena(), [${expected.join(", ")}], self.peek_n::<1>())),
            }
        }`
        }

        // B. Only if A failed, start LL(2) grammar analysis


        // C. Only if A and B failed, start LL(k) grammar analysis

        return `\
    fn parse_${rule.rustName}(&mut self) -> Result<${rule.rustName}, Self::Error> {
        todo!()
    }`
    }

    private generateProductMethod(rule: ProductRuleIR): string {
        const functionCalls: string[] = [];
        if (rule.elements === undefined) {
            return `\
    fn parse_${rule.rustName}(&mut self) -> Result<${rule.rustName}, Self::Error>;`
        }
        for (const [_, element] of rule.elements.entries()) {
            switch (element.kind) {
                case "NonTerminal":
                    const ruleName = element.targetRule;
                    let typeStr = this.getRustType(ruleName, element.modifier);
                    if (element.isBoxed) {
                        typeStr = `ArenaBox<${typeStr}>`;
                    }
                    switch (element.modifier) {
                        case "List":
                            functionCalls.push(`\
        let ${element.rustFieldName} = self.repeat(|this: &mut Self| this.parse_${ruleName}());`);
                            break;
                        case "Option":
                            functionCalls.push(`\
        let ${element.rustFieldName} = self.parse_${ruleName}().ok();`);
                            break;
                        case "None":
                            functionCalls.push(`\
        let ${element.rustFieldName} = self.parse_${ruleName}()?;`);
                            break;
                    }

                    break;
                case "Terminal":
                    const tokenType = TOKENS_MAP.get(element.value);
                    if (tokenType === undefined) {
                        throw new Error(`Unknown token type: ${element.value}`);
                    }
                    if (tokenType.includes("$")) {
                        throw new Error(`Token type with $..$ must parse manually. \nCreate new altanative for wrapping and implement by yourself.`)
                    }
                    functionCalls.push(`\
        self.expect_token(${tokenType})?;`);
                    break;
            }
        }
        return `\
    fn parse_${rule.rustName}(&mut self) -> Result<${rule.rustName}, Self::Error> {
${functionCalls.join('\n')}
        Ok(${rule.rustName} {
${rule.elements
                .filter((e): e is Extract<ElementIR, { kind: 'NonTerminal' }> => e.kind === 'NonTerminal')
                .map(v => (`    ${v.rustFieldName}`))}
        })
    }`;
    }

    private generateHookMethod(rule: HookIR): string {
        // TODO: implement hook definition
        return `\
    fn ${rule.methodName}(&mut self) -> Result<${rule.returnType}, Self::Error>;`
    }

    // -------------------------------------------------------------------------
    // Helpers
    // -------------------------------------------------------------------------

    private getRustType(ruleName: string, modifier: 'None' | 'List' | 'Option'): string {
        switch (modifier) {
            case 'List': return `ArenaIter<${ruleName}>`;
            case 'Option': return `Option<${ruleName}>`;
            case 'None': return ruleName;
        }
    }

    private makeUniqueName(name: string): string {
        this.unique_id += 1;
        return `${name}_${this.unique_id}`;
    }

    private getRuleFromName(name: string): RuleIR | undefined {
        const ret = this.ir.rules.get(name);
        return ret;
    }
}

export function generateParser(ir: GrammarIR): [string, string] {
    const generator = new RustParserGenerator(ir);
    return generator.generate();
}
